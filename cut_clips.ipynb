{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mera', 'naam', 'Saurabh', 'Braille', 'Ho', 'tapai', 'Ko', 'Khabar', 'Chha', 'I', 'love', 'you', 'Mero', 'Naam', 'Saurabh', 'Baral', 'home', 'The', 'Pi', 'Ko', 'Khabar', 'I', 'love', 'you', 'Mero', 'Naam', 'Saurabh', 'Baral', 'home', 'I', 'love', 'you', 'I', 'love', 'you', 'I', 'love', 'you', 'Khabar', 'ke', 'I', 'love', 'you']\n",
      "Split audio yoyo_split\\1_mera.wav created.\n",
      "Start Time0 End Time2669\n",
      "Split audio yoyo_split\\2_naam.wav created.\n",
      "Start Time2669 End Time5339\n",
      "Split audio yoyo_split\\3_Saurabh.wav created.\n",
      "Start Time5339 End Time8008\n",
      "Split audio yoyo_split\\4_Braille.wav created.\n",
      "Start Time8008 End Time10678\n",
      "Split audio yoyo_split\\5_Ho.wav created.\n",
      "Start Time10678 End Time13348\n",
      "Split audio yoyo_split\\6_tapai.wav created.\n",
      "Start Time13348 End Time16017\n",
      "Split audio yoyo_split\\7_Ko.wav created.\n",
      "Start Time16017 End Time18687\n",
      "Split audio yoyo_split\\8_Khabar.wav created.\n",
      "Start Time18687 End Time21357\n",
      "Split audio yoyo_split\\9_Chha.wav created.\n",
      "Start Time21357 End Time24026\n",
      "Split audio yoyo_split\\10_I.wav created.\n",
      "Start Time24026 End Time26696\n",
      "Split audio yoyo_split\\11_love.wav created.\n",
      "Start Time26696 End Time29366\n",
      "Split audio yoyo_split\\12_you.wav created.\n",
      "Start Time29366 End Time32035\n",
      "Split audio yoyo_split\\13_Mero.wav created.\n",
      "Start Time32035 End Time34705\n",
      "Split audio yoyo_split\\14_Naam.wav created.\n",
      "Start Time34705 End Time37375\n",
      "Split audio yoyo_split\\15_Saurabh.wav created.\n",
      "Start Time37375 End Time40044\n",
      "Split audio yoyo_split\\16_Baral.wav created.\n",
      "Start Time40044 End Time42714\n",
      "Split audio yoyo_split\\17_home.wav created.\n",
      "Start Time42714 End Time45384\n",
      "Split audio yoyo_split\\18_The.wav created.\n",
      "Start Time45384 End Time48053\n",
      "Split audio yoyo_split\\19_Pi.wav created.\n",
      "Start Time48053 End Time50723\n",
      "Split audio yoyo_split\\20_Ko.wav created.\n",
      "Start Time50723 End Time53393\n",
      "Split audio yoyo_split\\21_Khabar.wav created.\n",
      "Start Time53393 End Time56062\n",
      "Split audio yoyo_split\\22_I.wav created.\n",
      "Start Time56062 End Time58732\n",
      "Split audio yoyo_split\\23_love.wav created.\n",
      "Start Time58732 End Time61401\n",
      "Split audio yoyo_split\\24_you.wav created.\n",
      "Start Time61401 End Time64071\n",
      "Split audio yoyo_split\\25_Mero.wav created.\n",
      "Start Time64071 End Time66741\n",
      "Split audio yoyo_split\\26_Naam.wav created.\n",
      "Start Time66741 End Time69410\n",
      "Split audio yoyo_split\\27_Saurabh.wav created.\n",
      "Start Time69410 End Time72080\n",
      "Split audio yoyo_split\\28_Baral.wav created.\n",
      "Start Time72080 End Time74750\n",
      "Split audio yoyo_split\\29_home.wav created.\n",
      "Start Time74750 End Time77419\n",
      "Split audio yoyo_split\\30_I.wav created.\n",
      "Start Time77419 End Time80089\n",
      "Split audio yoyo_split\\31_love.wav created.\n",
      "Start Time80089 End Time82759\n",
      "Split audio yoyo_split\\32_you.wav created.\n",
      "Start Time82759 End Time85428\n",
      "Split audio yoyo_split\\33_I.wav created.\n",
      "Start Time85428 End Time88098\n",
      "Split audio yoyo_split\\34_love.wav created.\n",
      "Start Time88098 End Time90768\n",
      "Split audio yoyo_split\\35_you.wav created.\n",
      "Start Time90768 End Time93437\n",
      "Split audio yoyo_split\\36_I.wav created.\n",
      "Start Time93437 End Time96107\n",
      "Split audio yoyo_split\\37_love.wav created.\n",
      "Start Time96107 End Time98777\n",
      "Split audio yoyo_split\\38_you.wav created.\n",
      "Start Time98777 End Time101446\n",
      "Split audio yoyo_split\\39_Khabar.wav created.\n",
      "Start Time101446 End Time104116\n",
      "Split audio yoyo_split\\40_ke.wav created.\n",
      "Start Time104116 End Time106786\n",
      "Split audio yoyo_split\\41_I.wav created.\n",
      "Start Time106786 End Time109455\n",
      "Split audio yoyo_split\\42_love.wav created.\n",
      "Start Time109455 End Time112125\n",
      "Split audio yoyo_split\\43_you.wav created.\n",
      "Start Time112125 End Time114795\n",
      "Audio splitting completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def split_audio_by_words(audio_path):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_wav(audio_path)\n",
    "\n",
    "    # Initialize the recognizer\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    # Open the audio file\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "\n",
    "    # Perform speech recognition on the audio\n",
    "    result = recognizer.recognize_google(audio_data)\n",
    "\n",
    "    # Split the recognized text into words\n",
    "    words = result.split()\n",
    "\n",
    "    # Get the audio duration in milliseconds\n",
    "    audio_duration = len(audio)\n",
    "\n",
    "    # Create a directory to save the split audio files\n",
    "    output_dir = os.path.splitext(audio_path)[0] + \"_split\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(words)\n",
    "    # Split the audio based on word boundaries\n",
    "    for i, word in enumerate(words):\n",
    "        start_time = int(audio_duration / len(words) * i)\n",
    "        end_time = int(audio_duration / len(words) * (i + 1))\n",
    "        split_audio_path = os.path.join(output_dir, f\"{i+1}_{word}.wav\")\n",
    "\n",
    "        # Extract the segment of audio\n",
    "        split_audio = audio[start_time:end_time]\n",
    "\n",
    "        # Save the split audio to a file\n",
    "        split_audio.export(split_audio_path, format=\"wav\")\n",
    "\n",
    "        print(f\"Split audio {split_audio_path} created.\")\n",
    "        print(f\"Start Time{start_time} End Time{end_time}\")\n",
    "        \n",
    "\n",
    "    print(\"Audio splitting completed.\")\n",
    "\n",
    "# Provide the path to the audio file\n",
    "audio_path = \"yoyo.wav\"\n",
    "\n",
    "# Split the audio file by words\n",
    "split_audio_by_words(audio_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AudioData' object has no attribute 'result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\baral\\Desktop\\project\\cut_clips.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     audio_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhello.wav\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     word_times \u001b[39m=\u001b[39m detect_words(audio_file)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mif\u001b[39;00m word_times \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo words detected.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\baral\\Desktop\\project\\cut_clips.ipynb Cell 2\u001b[0m in \u001b[0;36mdetect_words\u001b[1;34m(audio_file)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m word_times \u001b[39m=\u001b[39m []\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m result \u001b[39m=\u001b[39m audio\u001b[39m.\u001b[39;49mresult\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m result:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     alternatives \u001b[39m=\u001b[39m result[\u001b[39m\"\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AudioData' object has no attribute 'result'"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def detect_words(audio_file):\n",
    "    \"\"\"Detects words in an audio file and returns the time intervals for each word.\"\"\"\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = r.record(source)\n",
    "    try:\n",
    "        words = r.recognize_google(audio)\n",
    "    except sr.UnknownValueError:\n",
    "        return None\n",
    "    word_times = []\n",
    "    result = audio.result\n",
    "    if \"alternative\" in result:\n",
    "        alternatives = result[\"alternative\"]\n",
    "        for alternative in alternatives:\n",
    "            word = alternative[\"transcript\"]\n",
    "            for word_info in alternative[\"words\"]:\n",
    "                start_time = word_info[\"start_time\"]\n",
    "                end_time = word_info[\"end_time\"]\n",
    "                word_times.append((word, start_time, end_time))\n",
    "    return word_times\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio_file = \"hello.wav\"\n",
    "    word_times = detect_words(audio_file)\n",
    "    if word_times is None:\n",
    "        print(\"No words detected.\")\n",
    "    else:\n",
    "        for word, start_time, end_time in word_times:\n",
    "            print(f\"Word: {word}, Start Time: {start_time:.2f} seconds, End Time: {end_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AudioData' object has no attribute 'timestamps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\baral\\Desktop\\project\\cut_clips.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     audio_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39myoyo.wav\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     word_times \u001b[39m=\u001b[39m detect_words(audio_file)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mfor\u001b[39;00m start_time, end_time \u001b[39min\u001b[39;00m word_times:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWord: \u001b[39m\u001b[39m{\u001b[39;00mword\u001b[39m}\u001b[39;00m\u001b[39m, Time: \u001b[39m\u001b[39m{\u001b[39;00mstart_time\u001b[39m}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m{\u001b[39;00mend_time\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\baral\\Desktop\\project\\cut_clips.ipynb Cell 3\u001b[0m in \u001b[0;36mdetect_words\u001b[1;34m(audio_file)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m word_times \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m words\u001b[39m.\u001b[39msplit():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     start_time, end_time \u001b[39m=\u001b[39m audio\u001b[39m.\u001b[39;49mtimestamps(word)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     word_times\u001b[39m.\u001b[39mappend((start_time, end_time))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/cut_clips.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m word_times\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AudioData' object has no attribute 'timestamps'"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import os\n",
    "\n",
    "def detect_words(audio_file):\n",
    "    \"\"\"Detects words in an audio file and returns the time intervals for each word.\"\"\"\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = r.record(source)\n",
    "    try:\n",
    "        words = r.recognize_google(audio)\n",
    "    except sr.UnknownValueError:\n",
    "        return None\n",
    "    word_times = []\n",
    "    for word in words.split():\n",
    "        start_time, end_time = audio.timestamps(word)[0]\n",
    "        word_times.append((start_time, end_time))\n",
    "    return word_times\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio_file = \"yoyo.wav\"\n",
    "    word_times = detect_words(audio_file)\n",
    "    for start_time, end_time in word_times:\n",
    "        print(f\"Word: {word}, Time: {start_time} - {end_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import speech_recognition as sr\n",
    "\n",
    "# def split_audio_by_words(audio_path):\n",
    "#     # Load the audio file\n",
    "#     audio = sr.AudioFile(audio_path)\n",
    "\n",
    "#     # Initialize the recognizer\n",
    "#     recognizer = sr.Recognizer()\n",
    "\n",
    "#     # Open the audio file\n",
    "#     with audio as source:\n",
    "#         audio_data = recognizer.record(source)\n",
    "\n",
    "#     # Perform speech recognition on the audio\n",
    "#     result = recognizer.recognize_google(audio_data)\n",
    "\n",
    "#     # Split the recognized text into words\n",
    "#     words = result.split()\n",
    "\n",
    "#     # Get the audio duration\n",
    "#     audio_duration = len(audio_data.frame_data) / audio_data.sample_rate\n",
    "\n",
    "#     # Create a directory to save the split audio files\n",
    "#     output_dir = os.path.splitext(audio_path)[0] + \"_split\"\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#     # Split the audio based on word boundaries\n",
    "#     for i, word in enumerate(words):\n",
    "#         start_time = int(audio_duration / len(words) * i)\n",
    "#         end_time = int(audio_duration / len(words) * (i + 1))\n",
    "#         split_audio_path = os.path.join(output_dir, f\"{i+1}_{word}.wav\")\n",
    "\n",
    "#         # Use FFmpeg to extract the segment of audio\n",
    "#         os.system(f\"ffmpeg -i {audio_path} -ss {start_time} -to {end_time} -c copy {split_audio_path}\")\n",
    "\n",
    "#         print(f\"Split audio {split_audio_path} created.\")\n",
    "\n",
    "#     print(\"Audio splitting completed.\")\n",
    "\n",
    "# # Provide the path to the audio file\n",
    "# audio_path = \"hello.wav\"\n",
    "\n",
    "# # Split the audio file by words\n",
    "# split_audio_by_words(audio_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
