{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snake game environment\n",
    "class SnakeGame:\n",
    "    def __init__(self, width, height):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.snake = [(self.width // 2, self.height // 2)]\n",
    "        self.direction = random.choice([(0, 1), (0, -1), (1, 0), (-1, 0)])\n",
    "        self.apple = self.generate_apple()\n",
    "        self.score = 0\n",
    "        self.done = False\n",
    "\n",
    "    def generate_apple(self):\n",
    "        while True:\n",
    "            apple = (random.randint(0, self.width - 1), random.randint(0, self.height - 1))\n",
    "            if apple not in self.snake:\n",
    "                return apple\n",
    "\n",
    "    def move(self, direction):\n",
    "        if not self.done:\n",
    "            new_head = (self.snake[0][0] + direction[0], self.snake[0][1] + direction[1])\n",
    "            if (0 <= new_head[0] < self.width) and (0 <= new_head[1] < self.height) and (new_head not in self.snake[1:]):\n",
    "                self.snake.insert(0, new_head)\n",
    "                if new_head == self.apple:\n",
    "                    self.score += 1\n",
    "                    self.apple = self.generate_apple()\n",
    "                else:\n",
    "                    self.snake.pop()\n",
    "            else:\n",
    "                self.done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Q-Network (DQN) model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experience replay memory\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        return states, actions, rewards, next_states, dones\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, batch_size, memory_capacity, gamma, epsilon_start, epsilon_end, epsilon_decay):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = ReplayMemory(memory_capacity)\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon_start\n",
    "        self.epsilon_end = epsilon_end\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = DQN(state_size, action_size).to(self.device)\n",
    "        self.target_model = DQN(state_size, action_size).to(self.device)\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        self.target_model.eval()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        self.loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if random.random() <= self.epsilon:\n",
    "            return random.randint(0, self.action_size - 1)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "                q_values = self.model(state)\n",
    "                return q_values.argmax().item()\n",
    "\n",
    "    def update_epsilon(self):\n",
    "        self.epsilon = max(self.epsilon_end, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "    def train(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        states, actions, rewards, next_states, dones = self.memory.sample(self.batch_size)\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.LongTensor(actions).unsqueeze(1).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).unsqueeze(1).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).unsqueeze(1).to(self.device)\n",
    "\n",
    "        current_q_values = self.model(states).gather(1, actions)\n",
    "        next_q_values = self.target_model(next_states).max(1)[0].unsqueeze(1)\n",
    "        target_q_values = rewards + (1 - dones) * self.gamma * next_q_values\n",
    "\n",
    "        loss = self.loss_fn(current_q_values, target_q_values)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        self.update_epsilon()\n",
    "\n",
    "        if len(self.memory) % 1000 == 0:\n",
    "            self.target_model.load_state_dict(self.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SnakeGame' object has no attribute 'snake_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\baral\\Desktop\\project\\snake.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m episode \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(NUM_EPISODES):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     game\u001b[39m.\u001b[39mreset()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     state \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(game\u001b[39m.\u001b[39;49msnake_to_array())\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     done \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     total_reward \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SnakeGame' object has no attribute 'snake_to_array'"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "WIDTH = 10\n",
    "HEIGHT = 10\n",
    "STATE_SIZE = WIDTH * HEIGHT\n",
    "ACTION_SIZE = 4  # up, down, left, right\n",
    "BATCH_SIZE = 64\n",
    "MEMORY_CAPACITY = 10000\n",
    "GAMMA = 0.99\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.01\n",
    "EPSILON_DECAY = 0.999\n",
    "\n",
    "# Training\n",
    "NUM_EPISODES = 1000\n",
    "MAX_STEPS = 100\n",
    "\n",
    "# Initialize game and agent\n",
    "game = SnakeGame(WIDTH, HEIGHT)\n",
    "agent = DQNAgent(STATE_SIZE, ACTION_SIZE, BATCH_SIZE, MEMORY_CAPACITY, GAMMA, EPSILON_START, EPSILON_END, EPSILON_DECAY)\n",
    "\n",
    "for episode in range(NUM_EPISODES):\n",
    "    game.reset()\n",
    "    state = np.array(game.snake_to_array()).flatten()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    for step in range(MAX_STEPS):\n",
    "        action = agent.get_action(state)\n",
    "        game.move([(0, -1), (0, 1), (-1, 0), (1, 0)][action])\n",
    "        next_state = np.array(game.snake_to_array()).flatten()\n",
    "        reward = game.score\n",
    "        done = game.done\n",
    "\n",
    "        agent.memory.push(state, action, reward, next_state, done)\n",
    "        total_reward += reward\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        agent.train()\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    print(f\"Episode: {episode+1}, Score: {total_reward}\")\n",
    "# Play the game using the trained agent\n",
    "game.reset()\n",
    "state = np.array(game.snake_to_array()).flatten()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "while not done:\n",
    "    action = agent.get_action(state)\n",
    "    game.move([(0, -1), (0, 1), (-1, 0), (1, 0)][action])\n",
    "    state = np.array(game.snake_to_array()).flatten()\n",
    "    total_reward += game.score\n",
    "    done = game.done\n",
    "\n",
    "print(f\"Total Score: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file or directory found at flappy_bird_model.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\baral\\Desktop\\project\\snake.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m load_model\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Load the trained model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39;49m\u001b[39mflappy_bird_model.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Rest of the code remains the same\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Main training loop\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m():\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[0;32m    231\u001b[0m         filepath,\n\u001b[0;32m    232\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[0;32m    233\u001b[0m         \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m,\n\u001b[0;32m    234\u001b[0m         safe_mode\u001b[39m=\u001b[39msafe_mode,\n\u001b[0;32m    235\u001b[0m     )\n\u001b[0;32m    237\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[0;32m    239\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39mcustom_objects, \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    240\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\saving\\legacy\\save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 234\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[0;32m    235\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m         )\n\u001b[0;32m    238\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    239\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[0;32m    240\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[0;32m    241\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at flappy_bird_model.h5"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _pywrap_tfe: The specified procedure could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\baral\\Desktop\\project\\snake.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m deque\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/baral/Desktop/project/snake.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\__init__.py:38\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m---> 38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m _os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mTF2_BEHAVIOR\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:32\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m coordination_config_pb2\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m rewriter_config_pb2\n\u001b[1;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tfe\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tf_session\n",
      "File \u001b[1;32mc:\\Users\\baral\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pywrap_tfe\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tfe: The specified procedure could not be found."
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Snake game environment\n",
    "class SnakeGame:\n",
    "    def __init__(self, width, height):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.snake = [(self.width // 2, self.height // 2)]\n",
    "        self.direction = random.choice([(0, 1), (0, -1), (1, 0), (-1, 0)])\n",
    "        self.apple = self.generate_apple()\n",
    "        self.score = 0\n",
    "        self.done = False\n",
    "\n",
    "    def generate_apple(self):\n",
    "        while True:\n",
    "            apple = (random.randint(0, self.width - 1), random.randint(0, self.height - 1))\n",
    "            if apple not in self.snake:\n",
    "                return apple\n",
    "\n",
    "    def move(self, direction):\n",
    "        if not self.done:\n",
    "            new_head = (self.snake[0][0] + direction[0], self.snake[0][1] + direction[1])\n",
    "            if (0 <= new_head[0] < self.width) and (0 <= new_head[1] < self.height) and (new_head not in self.snake[1:]):\n",
    "                self.snake.insert(0, new_head)\n",
    "                if new_head == self.apple:\n",
    "                    self.score += 1\n",
    "                    self.apple = self.generate_apple()\n",
    "                else:\n",
    "                    self.snake.pop()\n",
    "            else:\n",
    "                self.done = True\n",
    "\n",
    "    def get_state(self):\n",
    "        head = self.snake[0]\n",
    "        body = self.snake[1:]\n",
    "        state = [\n",
    "            # Check for obstacles and snake body around the head\n",
    "            (head[0] - 1, head[1]) in body or head[0] == 0,  # Left\n",
    "            (head[0] + 1, head[1]) in body or head[0] == self.width - 1,  # Right\n",
    "            (head[0], head[1] - 1) in body or head[1] == 0,  # Up\n",
    "            (head[0], head[1] + 1) in body or head[1] == self.height - 1,  # Down\n",
    "            # Check for apple location relative to the head\n",
    "            self.apple[0] < head[0],  # Apple to the left\n",
    "            self.apple[0] > head[0],  # Apple to the right\n",
    "            self.apple[1] < head[1],  # Apple above\n",
    "            self.apple[1] > head[1]  # Apple below\n",
    "        ]\n",
    "        return np.array(state, dtype=int)\n",
    "\n",
    "    def render(self):\n",
    "        pygame.init()\n",
    "        cell_size = 20\n",
    "        screen_width = self.width * cell_size\n",
    "        screen_height = self.height * cell_size\n",
    "        screen = pygame.display.set_mode((screen_width, screen_height))\n",
    "        pygame.display.set_caption(\"Snake Game\")\n",
    "\n",
    "        clock = pygame.time.Clock()\n",
    "\n",
    "        while not self.done:\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    self.done = True\n",
    "\n",
    "            screen.fill((0, 0, 0))  # Clear the screen\n",
    "\n",
    "            # Draw the snake\n",
    "            for segment in self.snake:\n",
    "                pygame.draw.rect(screen, (0, 255, 0), (segment[0] * cell_size, segment[1] * cell_size, cell_size, cell_size))\n",
    "\n",
    "            # Draw the apple\n",
    "            pygame.draw.rect(screen, (255, 0, 0), (self.apple[0] * cell_size, self.apple[1] * cell_size, cell_size, cell_size))\n",
    "\n",
    "            pygame.display.flip()  # Update the screen\n",
    "            clock.tick(10)  # Limit the frame rate\n",
    "\n",
    "            self.move(self.direction)  # Move the snake\n",
    "\n",
    "# Deep Q-Network (DQN) model\n",
    "class DQNModel:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95  # Discount factor\n",
    "        self.epsilon = 1.0  # Exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "# Constants\n",
    "WIDTH = 20\n",
    "HEIGHT = 20\n",
    "STATE_SIZE = 8  # Number of state features\n",
    "ACTION_SIZE = 4  # up, down, left, right\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Initialize game and agent\n",
    "game = SnakeGame(WIDTH, HEIGHT)\n",
    "model = DQNModel(STATE_SIZE, ACTION_SIZE)\n",
    "\n",
    "# Training\n",
    "for episode in range(1000):\n",
    "    state = game.get_state()\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        action = model.act(state)\n",
    "        game.move([(0, -1), (0, 1), (-1, 0), (1, 0)][action])\n",
    "        next_state = game.get_state()\n",
    "        reward = game.score - score\n",
    "        score = game.score\n",
    "        done = game.done\n",
    "        model.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(f\"Episode: {episode+1}, Score: {score}\")\n",
    "            break\n",
    "        if len(model.memory) > BATCH_SIZE:\n",
    "            model.replay(BATCH_SIZE)\n",
    "\n",
    "# Play the game using the trained agent\n",
    "game.reset()\n",
    "state = game.get_state()\n",
    "done = False\n",
    "\n",
    "pygame.init()\n",
    "cell_size = 20\n",
    "screen_width = WIDTH * cell_size\n",
    "screen_height = HEIGHT * cell_size\n",
    "screen = pygame.display.set_mode((screen_width, screen_height))\n",
    "pygame.display.set_caption(\"Snake Game\")\n",
    "\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "while not done:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            done = True\n",
    "\n",
    "    screen.fill((0, 0, 0))  # Clear the screen\n",
    "\n",
    "    # Draw the snake\n",
    "    for segment in game.snake:\n",
    "        pygame.draw.rect(screen, (0, 255, 0), (segment[0] * cell_size, segment[1] * cell_size, cell_size, cell_size))\n",
    "\n",
    "    # Draw the apple\n",
    "    pygame.draw.rect(screen, (255, 0, 0), (game.apple[0] * cell_size, game.apple[1] * cell_size, cell_size, cell_size))\n",
    "\n",
    "    pygame.display.flip()  # Update the screen\n",
    "    clock.tick(10)  # Limit the frame rate\n",
    "\n",
    "    action = model.act(np.reshape(state, [1, STATE_SIZE]))\n",
    "    game.move([(0, -1), (0, 1), (-1, 0), (1, 0)][action])\n",
    "    state = game.get_state()\n",
    "    done = game.done\n",
    "\n",
    "pygame.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
