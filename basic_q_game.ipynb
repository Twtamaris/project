{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((5,5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "WIDTH, HEIGHT = 8, 8\n",
    "CELL_SIZE = 100\n",
    "WIN_WIDTH, WIN_HEIGHT = WIDTH * CELL_SIZE, HEIGHT * CELL_SIZE\n",
    "FPS = 30\n",
    "OBSTACLES = [(1, 1), (2, 2), (3, 3)]  # Obstacle coordinates\n",
    "START_POS = (0, 0)  # Start position\n",
    "END_POS = (WIDTH - 1, HEIGHT - 1)  # End position\n",
    "ACTIONS = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"]\n",
    "EPSILON = 0.1  # Epsilon for exploration\n",
    "LEARNING_RATE = 0.1\n",
    "DISCOUNT_FACTOR = 0.9\n",
    "EPISODES = 1000\n",
    "\n",
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "window = pygame.display.set_mode((WIN_WIDTH, WIN_HEIGHT))\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "# Q-Table\n",
    "q_table = np.zeros((WIDTH, HEIGHT, len(ACTIONS)))\n",
    "\n",
    "# Helper function to draw the grid and obstacles\n",
    "def draw_grid():\n",
    "    for x in range(0, WIN_WIDTH, CELL_SIZE):\n",
    "        pygame.draw.line(window, (255, 255, 255), (x, 0), (x, WIN_HEIGHT))\n",
    "    for y in range(0, WIN_HEIGHT, CELL_SIZE):\n",
    "        pygame.draw.line(window, (255, 255, 255), (0, y), (WIN_WIDTH, y))\n",
    "    for obstacle in OBSTACLES:\n",
    "        pygame.draw.rect(window, (255, 0, 0), (obstacle[0] * CELL_SIZE, obstacle[1] * CELL_SIZE, CELL_SIZE, CELL_SIZE))\n",
    "\n",
    "# Function to choose an action based on the Q-values with epsilon-greedy policy\n",
    "def choose_action(state):\n",
    "    if np.random.rand() < EPSILON:\n",
    "        return random.choice(range(len(ACTIONS)))  # Explore\n",
    "    else:\n",
    "        return np.argmax(q_table[state])  # Exploit\n",
    "\n",
    "# Main Q-learning algorithm\n",
    "def q_learning():\n",
    "    global EPSILON  # Declare EPSILON as global to modify its value\n",
    "    for episode in range(EPISODES):\n",
    "        state = START_POS\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action = choose_action(state)\n",
    "            if action == 0:  # UP\n",
    "                next_state = (state[0], max(0, state[1] - 1))\n",
    "            elif action == 1:  # DOWN\n",
    "                next_state = (state[0], min(HEIGHT - 1, state[1] + 1))\n",
    "            elif action == 2:  # LEFT\n",
    "                next_state = (max(0, state[0] - 1), state[1])\n",
    "            else:  # RIGHT\n",
    "                next_state = (min(WIDTH - 1, state[0] + 1), state[1])\n",
    "\n",
    "            # Check for obstacles\n",
    "            if next_state not in OBSTACLES:\n",
    "                reward = -1  # Reward for moving to a valid state\n",
    "            else:\n",
    "                reward = -5  # Reward for moving to an invalid state\n",
    "\n",
    "            # Update Q-value using the Bellman equation\n",
    "            q_table[state][action] = (1 - LEARNING_RATE) * q_table[state][action] + \\\n",
    "                                     LEARNING_RATE * (reward + DISCOUNT_FACTOR * np.max(q_table[next_state]))\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "            # Check if the agent reached the goal\n",
    "            if state == END_POS:\n",
    "                done = True\n",
    "\n",
    "        # Reduce epsilon over time\n",
    "        EPSILON = max(0.1, EPSILON * 0.99)\n",
    "\n",
    "# Function to draw the agent on the grid\n",
    "def draw_agent(pos):\n",
    "    pygame.draw.rect(window, (0, 0, 255), (pos[0] * CELL_SIZE, pos[1] * CELL_SIZE, CELL_SIZE, CELL_SIZE))\n",
    "\n",
    "# Game loop\n",
    "def main():\n",
    "    q_learning()\n",
    "    current_pos = START_POS\n",
    "\n",
    "    running = True\n",
    "    while running:\n",
    "        window.fill((0, 0, 0))\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "\n",
    "        draw_grid()\n",
    "        draw_agent(current_pos)\n",
    "\n",
    "        # Move the agent based on the learned Q-values\n",
    "        action = np.argmax(q_table[current_pos])\n",
    "        if action == 0:  # UP\n",
    "            next_pos = (current_pos[0], max(0, current_pos[1] - 1))\n",
    "        elif action == 1:  # DOWN\n",
    "            next_pos = (current_pos[0], min(HEIGHT - 1, current_pos[1] + 1))\n",
    "        elif action == 2:  # LEFT\n",
    "            next_pos = (max(0, current_pos[0] - 1), current_pos[1])\n",
    "        else:  # RIGHT\n",
    "            next_pos = (min(WIDTH - 1, current_pos[0] + 1), current_pos[1])\n",
    "\n",
    "        # Check for obstacles\n",
    "        if next_pos not in OBSTACLES:\n",
    "            current_pos = next_pos\n",
    "\n",
    "        pygame.display.update()\n",
    "        clock.tick(FPS)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    pygame.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
